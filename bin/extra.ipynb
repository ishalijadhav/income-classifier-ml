{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2149a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "printX = logreg.fit(X_train, y_train, model__sample_weight=w_train)\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "y_prob_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression (baseline) ===\")\n",
    "print(classification_report(y_test, y_pred_lr, sample_weight=w_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_lr, sample_weight=w_test))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, y_prob_lr, sample_weight=w_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr, sample_weight=w_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef2765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "\n",
    "# === 3. Logistic Regression (with weights) ===\n",
    "logreg = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on training data\n",
    "logreg.fit(X_train, y_train, model__sample_weight=w_train)\n",
    "\n",
    "# --- Holdout evaluation ---\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "y_prob_lr = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression (weighted, Holdout) ===\")\n",
    "print(classification_report(y_test, y_pred_lr, sample_weight=w_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_lr, sample_weight=w_test))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, y_prob_lr, sample_weight=w_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr, sample_weight=w_test))\n",
    "\n",
    "# --- Cross-validation evaluation ---\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"pr_auc\": \"average_precision\"\n",
    "}\n",
    "\n",
    "cv_results_lr = cross_validate(\n",
    "    logreg,\n",
    "    X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    params={\"model__sample_weight\": w_train.to_numpy()}\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n=== Logistic Regression (weighted, Cross Validation) ===\")\n",
    "print(\"ROC-AUC: %.3f ± %.3f\" % (\n",
    "    cv_results_lr[\"test_roc_auc\"].mean(),\n",
    "    cv_results_lr[\"test_roc_auc\"].std()\n",
    "))\n",
    "print(\"PR-AUC : %.3f ± %.3f\" % (\n",
    "    cv_results_lr[\"test_pr_auc\"].mean(),\n",
    "    cv_results_lr[\"test_pr_auc\"].std()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_default = Pipeline([\n",
    "    (\"prep\", preprocessor),   # same preprocessing as before\n",
    "    (\"model\", DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit with weights\n",
    "dt_default.fit(X_train, y_train, model__sample_weight=w_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_default.predict(X_test)\n",
    "y_prob_dt = dt_default.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation (weighted)\n",
    "print(\"=== Decision Tree (Default Parameters, Holdout) ===\")\n",
    "print(classification_report(y_test, y_pred_dt, sample_weight=w_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_dt, sample_weight=w_test))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, y_prob_dt, sample_weight=w_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt, sample_weight=w_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "\n",
    "# Define scorers\n",
    "scoring = {\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"pr_auc\": \"average_precision\"\n",
    "}\n",
    "\n",
    "# Stratified CV so each fold has both classes\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Decision Tree pipeline\n",
    "dt = Pipeline([\n",
    "    (\"prep\", preprocessor),\n",
    "    (\"model\", DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    \"model__max_depth\": [3, 5, 10, 15,None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 5, 10]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit=\"roc_auc\",   # refit the best model according to ROC-AUC\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit with sample weights\n",
    "grid_dt.fit(X_train, y_train, model__sample_weight=w_train.to_numpy())\n",
    "\n",
    "# CV Results\n",
    "print(\"\\n=== Decision Tree CV Results ===\")\n",
    "print(\"Best Params:\", grid_dt.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", grid_dt.cv_results_['mean_test_roc_auc'][grid_dt.best_index_])\n",
    "print(\"Best CV PR-AUC :\", grid_dt.cv_results_['mean_test_pr_auc'][grid_dt.best_index_])\n",
    "\n",
    "# Holdout evaluation with best model\n",
    "best_dt = grid_dt.best_estimator_   \n",
    "\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "y_prob_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Decision Tree (Tuned, Holdout) ===\")\n",
    "print(classification_report(y_test, y_pred_dt, sample_weight=w_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_dt, sample_weight=w_test))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, y_prob_dt, sample_weight=w_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt, sample_weight=w_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e87100",
   "metadata": {},
   "source": [
    "## Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda5734f",
   "metadata": {},
   "source": [
    "feat_x = \"Age\"\n",
    "feat_y = \"Weekly_Working_Time\"\n",
    "\n",
    "# Subset data\n",
    "X_2d = df_labeled[[feat_x, feat_y]]\n",
    "y_2d = df_labeled[\"Income\"].astype(int)\n",
    "\n",
    "# Train a simple decision tree on just 2 features\n",
    "dt_2d = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dt_2d.fit(X_2d, y_2d)\n",
    "\n",
    "# Create grid for plotting decision surface\n",
    "x_min, x_max = X_2d[feat_x].min()-5, X_2d[feat_x].max()+5\n",
    "y_min, y_max = X_2d[feat_y].min()-5, X_2d[feat_y].max()+5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "Z = dt_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=\"coolwarm\")\n",
    "plt.scatter(X_2d[feat_x], X_2d[feat_y], c=y_2d, cmap=\"coolwarm\", edgecolor=\"k\", alpha=0.7)\n",
    "plt.xlabel(feat_x)\n",
    "plt.ylabel(feat_y)\n",
    "plt.title(\"Decision Boundary (Decision Tree, 2D projection)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67574570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest pipeline\n",
    "rf = Pipeline([\n",
    "    (\"prep\", tree_preprocessor),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit with weights\n",
    "rf.fit(X_train, y_train, model__sample_weight=w_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"=== Random Forest (Tree-Specific Preprocessing, Holdout) ===\")\n",
    "print(classification_report(y_test, y_pred_rf, sample_weight=w_test))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_rf, sample_weight=w_test))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, y_prob_rf, sample_weight=w_test))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf, sample_weight=w_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Handle Missing Values with DecisionTreeClassifier Imputer\n",
    "# =====================================================\n",
    "\n",
    "# --- Step 4: Rebuild preprocessing pipeline (no imputers needed now) ---\n",
    "regular_cat_tf = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "num_plain_tf = StandardScaler()\n",
    "\n",
    "num_log_tf = Pipeline([\n",
    "    (\"log\", FunctionTransformer(np.log1p, validate=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", regular_cat_tf, cat_cols),\n",
    "    (\"num_plain\", num_plain_tf, num_plain),\n",
    "    (\"num_log\", num_log_tf, num_log)\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
